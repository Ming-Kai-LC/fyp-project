{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18 - CrossViT Enhancement (Phase 2)\n",
    "\n",
    "**Author:** Tan Ming Kai (24PMR12003)  \n",
    "**Date:** 2025-11-26  \n",
    "**Purpose:** Train enhanced CrossViT models with 24GB VRAM\n",
    "\n",
    "**Models:**\n",
    "- CrossViT-Base (105M parameters) - HIGHEST PRIORITY\n",
    "- CrossViT-Small (26M parameters) - Backup\n",
    "\n",
    "**Expected Results:**\n",
    "- CrossViT-Tiny (current): 94.96%\n",
    "- CrossViT-Base: 96-97% (target)\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "1. Train CrossViT-Base with 5 random seeds\n",
    "2. Train CrossViT-Small with 5 random seeds (if time permits)\n",
    "3. Implement ensemble prediction (5 models averaged)\n",
    "4. Implement Test-Time Augmentation (TTA)\n",
    "5. Combine Ensemble + TTA for maximum accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os, sys, random, time, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import timm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.pytorch\n",
    "    MLFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MLFLOW_AVAILABLE = False\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(f\"PyTorch {torch.__version__} | CUDA: {torch.cuda.is_available()}\")\n",
    "print(f\"timm {timm.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardware verification\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"VRAM: {vram_gb:.2f} GB\")\n",
    "    \n",
    "    # Determine batch size based on VRAM\n",
    "    if vram_gb >= 24:\n",
    "        BASE_BATCH_SIZE = 32\n",
    "        SMALL_BATCH_SIZE = 64\n",
    "        print(f\"[OK] 24GB+ VRAM detected - Using optimal batch sizes\")\n",
    "    elif vram_gb >= 16:\n",
    "        BASE_BATCH_SIZE = 16\n",
    "        SMALL_BATCH_SIZE = 32\n",
    "        print(f\"[OK] 16GB+ VRAM detected - Using reduced batch sizes\")\n",
    "    else:\n",
    "        BASE_BATCH_SIZE = 8\n",
    "        SMALL_BATCH_SIZE = 16\n",
    "        print(f\"[WARN] <16GB VRAM - Using minimal batch sizes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CSV_DIR = Path(\"../data/processed\")\n",
    "MODELS_DIR = Path(\"../models\")\n",
    "RESULTS_DIR = Path(\"../results\")\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# CrossViT-Base Configuration (24GB VRAM optimized)\n",
    "CONFIG_BASE = {\n",
    "    'device': device,\n",
    "    'model_name': 'CrossViT-Base',\n",
    "    'timm_model': 'crossvit_base_240',\n",
    "    'num_classes': 4,\n",
    "    'image_size': 240,\n",
    "    'class_names': ['COVID', 'Normal', 'Lung_Opacity', 'Viral Pneumonia'],\n",
    "    'class_weights': [1.47, 0.52, 0.88, 3.95],\n",
    "    'batch_size': BASE_BATCH_SIZE,\n",
    "    'num_workers': 0,  # Windows compatibility\n",
    "    'learning_rate': 5e-5,\n",
    "    'weight_decay': 0.05,\n",
    "    'max_epochs': 50,\n",
    "    'early_stopping_patience': 15,\n",
    "    'mean': [0.485, 0.456, 0.406],\n",
    "    'std': [0.229, 0.224, 0.225],\n",
    "    'mixed_precision': True,\n",
    "    'seeds': [42, 123, 456, 789, 101112],\n",
    "}\n",
    "\n",
    "# CrossViT-Small Configuration\n",
    "CONFIG_SMALL = CONFIG_BASE.copy()\n",
    "CONFIG_SMALL.update({\n",
    "    'model_name': 'CrossViT-Small',\n",
    "    'timm_model': 'crossvit_small_240',\n",
    "    'batch_size': SMALL_BATCH_SIZE,\n",
    "})\n",
    "\n",
    "print(f\"CrossViT-Base: batch_size={CONFIG_BASE['batch_size']}\")\n",
    "print(f\"CrossViT-Small: batch_size={CONFIG_SMALL['batch_size']}\")\n",
    "print(f\"Seeds: {CONFIG_BASE['seeds']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow setup\n",
    "if MLFLOW_AVAILABLE:\n",
    "    mlflow.set_experiment(\"crossvit-covid19-classification\")\n",
    "    mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "    print(\"[OK] MLflow configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(CSV_DIR / \"train.csv\")\n",
    "val_df = pd.read_csv(CSV_DIR / \"val.csv\")\n",
    "test_df = pd.read_csv(CSV_DIR / \"test.csv\")\n",
    "print(f\"Train: {len(train_df):,} | Val: {len(val_df):,} | Test: {len(test_df):,}\")\n",
    "\n",
    "# Verify paths exist\n",
    "sample_path = train_df['image_path'].iloc[0]\n",
    "if os.path.exists(sample_path):\n",
    "    print(f\"[OK] Path verification passed\")\n",
    "else:\n",
    "    print(f\"[ERROR] Path not found: {sample_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class with on-the-fly CLAHE\n",
    "class COVID19Dataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.image_paths = dataframe['image_path'].values\n",
    "        self.labels = dataframe['label'].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Could not load: {img_path}\")\n",
    "        \n",
    "        # Convert to grayscale if needed\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image\n",
    "        \n",
    "        # Apply CLAHE\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        enhanced = clahe.apply(gray)\n",
    "        \n",
    "        # Convert to RGB\n",
    "        rgb_image = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2RGB)\n",
    "        image = Image.fromarray(rgb_image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "print(\"[OK] Dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms for 240x240 input (CrossViT requirement)\n",
    "def get_transforms(config, is_train=True):\n",
    "    if is_train:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((config['image_size'], config['image_size'])),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=config['mean'], std=config['std'])\n",
    "        ])\n",
    "    else:\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((config['image_size'], config['image_size'])),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=config['mean'], std=config['std'])\n",
    "        ])\n",
    "\n",
    "print(\"[OK] Transforms defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device, scaler=None, epoch=0):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(loader, desc=f\"Epoch {epoch+1} [Train]\")\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': running_loss / (batch_idx + 1), 'acc': 100. * correct / total})\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device, desc=\"Val\"):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=f\"[{desc}]\"):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total, np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "print(\"[OK] Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single seed training function\n",
    "def train_crossvit_single_seed(seed, config):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TRAINING {config['model_name']} WITH SEED {seed}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    set_seed(seed)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_transform = get_transforms(config, is_train=True)\n",
    "    val_transform = get_transforms(config, is_train=False)\n",
    "    \n",
    "    train_dataset = COVID19Dataset(train_df, transform=train_transform)\n",
    "    val_dataset = COVID19Dataset(val_df, transform=val_transform)\n",
    "    test_dataset = COVID19Dataset(test_df, transform=val_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], \n",
    "                              shuffle=True, num_workers=config['num_workers'], \n",
    "                              pin_memory=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], \n",
    "                            shuffle=False, num_workers=config['num_workers'],\n",
    "                            pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], \n",
    "                             shuffle=False, num_workers=config['num_workers'],\n",
    "                             pin_memory=True)\n",
    "    \n",
    "    # Load model\n",
    "    model = timm.create_model(config['timm_model'], pretrained=True, num_classes=config['num_classes'])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"[OK] {config['model_name']} loaded: {num_params:,} parameters\")\n",
    "    \n",
    "    # Loss, optimizer, scheduler\n",
    "    class_weights = torch.tensor(config['class_weights'], dtype=torch.float32).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "    scaler = torch.cuda.amp.GradScaler() if config['mixed_precision'] else None\n",
    "    \n",
    "    # MLflow\n",
    "    if MLFLOW_AVAILABLE:\n",
    "        try:\n",
    "            mlflow.end_run()\n",
    "        except:\n",
    "            pass\n",
    "        mlflow.start_run(run_name=f\"{config['timm_model']}-seed-{seed}\")\n",
    "        mlflow.log_param(\"model\", config['model_name'])\n",
    "        mlflow.log_param(\"timm_model\", config['timm_model'])\n",
    "        mlflow.log_param(\"random_seed\", seed)\n",
    "        mlflow.log_param(\"batch_size\", config['batch_size'])\n",
    "        mlflow.log_param(\"learning_rate\", config['learning_rate'])\n",
    "        mlflow.log_param(\"num_params\", num_params)\n",
    "        mlflow.set_tag(\"phase\", \"Phase 2 - CrossViT Enhancement\")\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    model_filename = f\"{config['timm_model'].replace('-', '_')}_best_seed{seed}.pth\"\n",
    "    best_model_path = MODELS_DIR / model_filename\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(config['max_epochs']):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, scaler, epoch)\n",
    "        val_loss, val_acc, _, _ = validate(model, val_loader, criterion, device)\n",
    "        scheduler.step()\n",
    "        \n",
    "        if MLFLOW_AVAILABLE:\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "            mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "            mlflow.log_metric(\"val_acc\", val_acc, step=epoch)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f} Acc={train_acc:.2f}% | Val Loss={val_loss:.4f} Acc={val_acc:.2f}%\")\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(\"[OK] Best model saved!\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= config['early_stopping_patience']:\n",
    "                print(f\"[STOP] Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Test evaluation\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    test_loss, test_acc, test_preds, test_labels = validate(model, test_loader, criterion, device, desc=\"Test\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(test_labels, test_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=config['class_names'], yticklabels=config['class_names'])\n",
    "    plt.ylabel('True'); plt.xlabel('Predicted')\n",
    "    plt.title(f\"{config['model_name']} Confusion Matrix (Seed {seed})\")\n",
    "    cm_path = RESULTS_DIR / f\"{config['timm_model'].replace('-', '_')}_cm_seed{seed}.png\"\n",
    "    plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    if MLFLOW_AVAILABLE:\n",
    "        mlflow.log_metric(\"test_loss\", test_loss)\n",
    "        mlflow.log_metric(\"test_accuracy\", test_acc)\n",
    "        mlflow.log_metric(\"training_time_minutes\", training_time / 60)\n",
    "        mlflow.log_artifact(str(cm_path))\n",
    "        mlflow.end_run()\n",
    "    \n",
    "    print(f\"[OK] Seed {seed} complete: Test Acc = {test_acc:.2f}%\")\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return {\n",
    "        'seed': seed,\n",
    "        'test_acc': test_acc,\n",
    "        'test_loss': test_loss,\n",
    "        'training_time': training_time,\n",
    "        'model_path': str(best_model_path)\n",
    "    }\n",
    "\n",
    "print(\"[OK] Single seed training function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Train CrossViT-Base (5 seeds)\n",
    "\n",
    "CrossViT-Base is the largest CrossViT variant with ~105M parameters.\n",
    "Expected accuracy: 96-97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify CrossViT-Base model\n",
    "print(\"Verifying CrossViT-Base model...\")\n",
    "test_model = timm.create_model('crossvit_base_240', pretrained=True, num_classes=4)\n",
    "print(f\"Model: {CONFIG_BASE['timm_model']}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in test_model.parameters()):,}\")\n",
    "\n",
    "# Test forward pass\n",
    "test_model = test_model.to(device)\n",
    "test_input = torch.randn(2, 3, 240, 240).to(device)\n",
    "with torch.no_grad():\n",
    "    test_output = test_model(test_input)\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "print(f\"Output shape: {test_output.shape}\")\n",
    "print(f\"VRAM used: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "\n",
    "del test_model, test_input, test_output\n",
    "torch.cuda.empty_cache()\n",
    "print(\"[OK] CrossViT-Base verification passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CrossViT-Base with all seeds\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"STARTING CROSSVIT-BASE MULTI-SEED TRAINING\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Model: {CONFIG_BASE['timm_model']}\")\n",
    "print(f\"Batch size: {CONFIG_BASE['batch_size']}\")\n",
    "print(f\"Seeds: {CONFIG_BASE['seeds']}\")\n",
    "print()\n",
    "\n",
    "base_results = []\n",
    "for seed in CONFIG_BASE['seeds']:\n",
    "    try:\n",
    "        result = train_crossvit_single_seed(seed, CONFIG_BASE)\n",
    "        base_results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Seed {seed}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"CROSSVIT-BASE TRAINING COMPLETED\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrossViT-Base statistical analysis\n",
    "if base_results:\n",
    "    accuracies = [r['test_acc'] for r in base_results]\n",
    "    mean_acc = np.mean(accuracies)\n",
    "    std_acc = np.std(accuracies, ddof=1)\n",
    "    \n",
    "    print(f\"\\n CrossViT-Base Results ({len(base_results)} seeds):\")\n",
    "    print(f\"   Mean +/- Std: {mean_acc:.2f}% +/- {std_acc:.2f}%\")\n",
    "    print(f\"   Range: [{np.min(accuracies):.2f}%, {np.max(accuracies):.2f}%]\")\n",
    "    \n",
    "    # Save results\n",
    "    results_df = pd.DataFrame(base_results)\n",
    "    results_path = RESULTS_DIR / \"crossvit_base_results.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    print(f\"\\n[OK] Results saved to {results_path}\")\n",
    "    print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Train CrossViT-Small (5 seeds) - Optional\n",
    "\n",
    "CrossViT-Small is a mid-size variant with ~26M parameters.\n",
    "Expected accuracy: 95.5-96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CrossViT-Small with all seeds\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"STARTING CROSSVIT-SMALL MULTI-SEED TRAINING\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Model: {CONFIG_SMALL['timm_model']}\")\n",
    "print(f\"Batch size: {CONFIG_SMALL['batch_size']}\")\n",
    "print(f\"Seeds: {CONFIG_SMALL['seeds']}\")\n",
    "print()\n",
    "\n",
    "small_results = []\n",
    "for seed in CONFIG_SMALL['seeds']:\n",
    "    try:\n",
    "        result = train_crossvit_single_seed(seed, CONFIG_SMALL)\n",
    "        small_results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Seed {seed}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"CROSSVIT-SMALL TRAINING COMPLETED\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrossViT-Small statistical analysis\n",
    "if small_results:\n",
    "    accuracies = [r['test_acc'] for r in small_results]\n",
    "    mean_acc = np.mean(accuracies)\n",
    "    std_acc = np.std(accuracies, ddof=1)\n",
    "    \n",
    "    print(f\"\\n CrossViT-Small Results ({len(small_results)} seeds):\")\n",
    "    print(f\"   Mean +/- Std: {mean_acc:.2f}% +/- {std_acc:.2f}%\")\n",
    "    print(f\"   Range: [{np.min(accuracies):.2f}%, {np.max(accuracies):.2f}%]\")\n",
    "    \n",
    "    # Save results\n",
    "    results_df = pd.DataFrame(small_results)\n",
    "    results_path = RESULTS_DIR / \"crossvit_small_results.csv\"\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    print(f\"\\n[OK] Results saved to {results_path}\")\n",
    "    print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Ensemble Prediction\n",
    "\n",
    "Combine predictions from all 5 models (seeds) to improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble prediction functions\n",
    "def load_ensemble_models(model_paths, timm_model, num_classes=4, device='cuda'):\n",
    "    \"\"\"Load multiple models for ensemble prediction.\"\"\"\n",
    "    models = []\n",
    "    for path in model_paths:\n",
    "        model = timm.create_model(timm_model, pretrained=False, num_classes=num_classes)\n",
    "        model.load_state_dict(torch.load(path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def ensemble_predict_batch(models, images, device='cuda'):\n",
    "    \"\"\"Average predictions from all models for a batch.\"\"\"\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for model in models:\n",
    "            output = model(images.to(device))\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            all_probs.append(probs)\n",
    "    \n",
    "    avg_probs = torch.stack(all_probs).mean(dim=0)\n",
    "    return avg_probs\n",
    "\n",
    "def evaluate_ensemble(models, loader, device='cuda'):\n",
    "    \"\"\"Evaluate ensemble on test set.\"\"\"\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Ensemble Eval\"):\n",
    "        avg_probs = ensemble_predict_batch(models, images, device)\n",
    "        preds = avg_probs.argmax(dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds) * 100\n",
    "    return accuracy, np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "print(\"[OK] Ensemble functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate CrossViT-Base ensemble (if trained)\n",
    "if base_results:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CROSSVIT-BASE ENSEMBLE EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    model_paths = [r['model_path'] for r in base_results]\n",
    "    print(f\"Loading {len(model_paths)} models...\")\n",
    "    \n",
    "    ensemble_models = load_ensemble_models(model_paths, CONFIG_BASE['timm_model'], device=device)\n",
    "    \n",
    "    val_transform = get_transforms(CONFIG_BASE, is_train=False)\n",
    "    test_dataset = COVID19Dataset(test_df, transform=val_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CONFIG_BASE['batch_size'], \n",
    "                             shuffle=False, num_workers=0)\n",
    "    \n",
    "    ensemble_acc, ensemble_preds, ensemble_labels = evaluate_ensemble(ensemble_models, test_loader, device)\n",
    "    \n",
    "    print(f\"\\n CrossViT-Base Ensemble Accuracy: {ensemble_acc:.2f}%\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(ensemble_labels, ensemble_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=CONFIG_BASE['class_names'], yticklabels=CONFIG_BASE['class_names'])\n",
    "    plt.ylabel('True'); plt.xlabel('Predicted')\n",
    "    plt.title(f\"CrossViT-Base Ensemble Confusion Matrix (Acc: {ensemble_acc:.2f}%)\")\n",
    "    plt.savefig(RESULTS_DIR / \"crossvit_base_ensemble_cm.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Clean up\n",
    "    del ensemble_models\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Test-Time Augmentation (TTA)\n",
    "\n",
    "Apply multiple augmentations at test time and average predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA functions\n",
    "def predict_with_tta(model, image_tensor, device='cuda'):\n",
    "    \"\"\"5-fold TTA: original + 4 augmentations.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    augmentations = [\n",
    "        lambda x: x,                                    # Original\n",
    "        lambda x: torch.flip(x, dims=[-1]),            # Horizontal flip\n",
    "        lambda x: torch.flip(x, dims=[-2]),            # Vertical flip\n",
    "        lambda x: torch.rot90(x, k=1, dims=[-2, -1]),  # Rotate 90\n",
    "        lambda x: torch.rot90(x, k=3, dims=[-2, -1]),  # Rotate -90\n",
    "    ]\n",
    "    \n",
    "    all_probs = []\n",
    "    with torch.no_grad():\n",
    "        for aug in augmentations:\n",
    "            aug_img = aug(image_tensor).to(device)\n",
    "            output = model(aug_img)\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            all_probs.append(probs)\n",
    "    \n",
    "    return torch.stack(all_probs).mean(dim=0)\n",
    "\n",
    "def evaluate_tta(model, loader, device='cuda'):\n",
    "    \"\"\"Evaluate single model with TTA.\"\"\"\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"TTA Eval\"):\n",
    "        tta_probs = predict_with_tta(model, images, device)\n",
    "        preds = tta_probs.argmax(dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds) * 100\n",
    "    return accuracy, np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "print(\"[OK] TTA functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate CrossViT-Base best model with TTA\n",
    "if base_results:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CROSSVIT-BASE TTA EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load best model (highest accuracy)\n",
    "    best_result = max(base_results, key=lambda x: x['test_acc'])\n",
    "    print(f\"Best seed: {best_result['seed']} (Acc: {best_result['test_acc']:.2f}%)\")\n",
    "    \n",
    "    model = timm.create_model(CONFIG_BASE['timm_model'], pretrained=False, num_classes=4)\n",
    "    model.load_state_dict(torch.load(best_result['model_path']))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    val_transform = get_transforms(CONFIG_BASE, is_train=False)\n",
    "    test_dataset = COVID19Dataset(test_df, transform=val_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CONFIG_BASE['batch_size'], \n",
    "                             shuffle=False, num_workers=0)\n",
    "    \n",
    "    tta_acc, tta_preds, tta_labels = evaluate_tta(model, test_loader, device)\n",
    "    \n",
    "    print(f\"\\n CrossViT-Base TTA Accuracy: {tta_acc:.2f}%\")\n",
    "    print(f\"   Improvement over base: {tta_acc - best_result['test_acc']:.2f}%\")\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Ensemble + TTA (Maximum Accuracy)\n",
    "\n",
    "Combine all 5 models with TTA = 25 predictions averaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Ensemble + TTA\n",
    "def ensemble_tta_predict_batch(models, images, device='cuda'):\n",
    "    \"\"\"Combine all models with TTA.\"\"\"\n",
    "    all_probs = []\n",
    "    \n",
    "    for model in models:\n",
    "        tta_probs = predict_with_tta(model, images, device)\n",
    "        all_probs.append(tta_probs)\n",
    "    \n",
    "    return torch.stack(all_probs).mean(dim=0)\n",
    "\n",
    "def evaluate_ensemble_tta(models, loader, device='cuda'):\n",
    "    \"\"\"Evaluate ensemble with TTA.\"\"\"\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Ensemble+TTA Eval\"):\n",
    "        avg_probs = ensemble_tta_predict_batch(models, images, device)\n",
    "        preds = avg_probs.argmax(dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds) * 100\n",
    "    return accuracy, np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "print(\"[OK] Ensemble+TTA functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate CrossViT-Base Ensemble + TTA\n",
    "if base_results:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CROSSVIT-BASE ENSEMBLE + TTA EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    model_paths = [r['model_path'] for r in base_results]\n",
    "    print(f\"Loading {len(model_paths)} models for Ensemble+TTA (25 predictions per sample)...\")\n",
    "    \n",
    "    ensemble_models = load_ensemble_models(model_paths, CONFIG_BASE['timm_model'], device=device)\n",
    "    \n",
    "    val_transform = get_transforms(CONFIG_BASE, is_train=False)\n",
    "    test_dataset = COVID19Dataset(test_df, transform=val_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)  # Smaller batch for memory\n",
    "    \n",
    "    ensemble_tta_acc, ensemble_tta_preds, ensemble_tta_labels = evaluate_ensemble_tta(\n",
    "        ensemble_models, test_loader, device)\n",
    "    \n",
    "    print(f\"\\n CrossViT-Base Ensemble+TTA Accuracy: {ensemble_tta_acc:.2f}%\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(ensemble_tta_labels, ensemble_tta_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=CONFIG_BASE['class_names'], yticklabels=CONFIG_BASE['class_names'])\n",
    "    plt.ylabel('True'); plt.xlabel('Predicted')\n",
    "    plt.title(f\"CrossViT-Base Ensemble+TTA Confusion Matrix (Acc: {ensemble_tta_acc:.2f}%)\")\n",
    "    plt.savefig(RESULTS_DIR / \"crossvit_base_ensemble_tta_cm.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    del ensemble_models\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CROSSVIT ENHANCEMENT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "# CrossViT-Tiny baseline (from previous experiments)\n",
    "summary_data.append({\n",
    "    'Method': 'CrossViT-Tiny (Baseline)',\n",
    "    'Accuracy': 94.96,\n",
    "    'Notes': 'Previous result'\n",
    "})\n",
    "\n",
    "if base_results:\n",
    "    base_accs = [r['test_acc'] for r in base_results]\n",
    "    summary_data.append({\n",
    "        'Method': 'CrossViT-Base (Single)',\n",
    "        'Accuracy': np.mean(base_accs),\n",
    "        'Notes': f'{len(base_results)} seeds, std={np.std(base_accs, ddof=1):.2f}'\n",
    "    })\n",
    "\n",
    "if 'ensemble_acc' in dir():\n",
    "    summary_data.append({\n",
    "        'Method': 'CrossViT-Base Ensemble',\n",
    "        'Accuracy': ensemble_acc,\n",
    "        'Notes': '5 models averaged'\n",
    "    })\n",
    "\n",
    "if 'tta_acc' in dir():\n",
    "    summary_data.append({\n",
    "        'Method': 'CrossViT-Base + TTA',\n",
    "        'Accuracy': tta_acc,\n",
    "        'Notes': 'Best seed + 5-fold TTA'\n",
    "    })\n",
    "\n",
    "if 'ensemble_tta_acc' in dir():\n",
    "    summary_data.append({\n",
    "        'Method': 'CrossViT-Base Ensemble+TTA',\n",
    "        'Accuracy': ensemble_tta_acc,\n",
    "        'Notes': '5 models x 5 TTA = 25 predictions'\n",
    "    })\n",
    "\n",
    "if small_results:\n",
    "    small_accs = [r['test_acc'] for r in small_results]\n",
    "    summary_data.append({\n",
    "        'Method': 'CrossViT-Small (Single)',\n",
    "        'Accuracy': np.mean(small_accs),\n",
    "        'Notes': f'{len(small_results)} seeds'\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values('Accuracy', ascending=False)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv(RESULTS_DIR / \"crossvit_enhancement_summary.csv\", index=False)\n",
    "print(f\"\\n[OK] Summary saved to {RESULTS_DIR / 'crossvit_enhancement_summary.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CROSSVIT ENHANCEMENT COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
