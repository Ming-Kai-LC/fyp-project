{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 00 - Environment Setup & Verification\n\n**Author:** Tan Ming Kai (24PMR12003)  \n**Date:** 2025-11-09  \n**Purpose:** Verify GPU, dependencies, and environment configuration for CrossViT COVID-19 FYP\n\n**Project:** Multi-Scale Vision Transformer (CrossViT) for COVID-19 Chest X-ray Classification  \n**Hardware:** RTX 4060 8GB VRAM  \n**Academic Year:** 2025/26\n\n---\n\n## Objectives\n1. âœ… Verify GPU availability and CUDA compatibility\n2. âœ… Check all required dependencies\n3. âœ… Test CrossViT model loading from timm\n4. âœ… Validate dataset paths\n5. âœ… Set up reproducibility configuration\n6. âœ… Test memory monitoring utilities\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Reproducibility Setup & Critical Imports\n\n**CRITICAL:** This section MUST run first in ALL notebooks to ensure reproducible results."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nEnvironment Setup Notebook for CrossViT COVID-19 FYP\nAuthor: Tan Ming Kai (24PMR12003)\nPurpose: Verify all dependencies and hardware before starting data pipeline\n\"\"\"\n\n# ============================================================================\n# 1. REPRODUCIBILITY SETUP (ALWAYS FIRST!)\n# ============================================================================\nimport random\nimport numpy as np\nimport torch\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nprint(\"âœ… Random seeds set to 42 for reproducibility\")\n\n# ============================================================================\n# 2. STANDARD LIBRARY IMPORTS\n# ============================================================================\nimport os\nimport sys\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# 3. DATA SCIENCE LIBRARIES\n# ============================================================================\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configure display options\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\n# Set plotting style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette('husl')\n\n# ============================================================================\n# 4. COMPUTER VISION LIBRARIES\n# ============================================================================\nimport cv2\nfrom PIL import Image\nimport timm  # For CrossViT model\n\n# ============================================================================\n# 5. PYTORCH & DEEP LEARNING\n# ============================================================================\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\n\nprint(\"\\nâœ… All imports successful!\")\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"OpenCV version: {cv2.__version__}\")\nprint(f\"Timm version: {timm.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. GPU & CUDA Verification\n\n**Expected Hardware:** NVIDIA RTX 4060 with 8GB VRAM"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check CUDA availability\nprint(\"=\" * 70)\nprint(\"GPU & CUDA VERIFICATION\")\nprint(\"=\" * 70)\n\ncuda_available = torch.cuda.is_available()\nprint(f\"\\nâœ“ CUDA Available: {cuda_available}\")\n\nif cuda_available:\n    # Get GPU details\n    gpu_name = torch.cuda.get_device_name(0)\n    gpu_count = torch.cuda.device_count()\n    cuda_version = torch.version.cuda\n    \n    print(f\"âœ“ GPU Name: {gpu_name}\")\n    print(f\"âœ“ GPU Count: {gpu_count}\")\n    print(f\"âœ“ CUDA Version: {cuda_version}\")\n    \n    # Get VRAM information\n    gpu_properties = torch.cuda.get_device_properties(0)\n    total_memory_gb = gpu_properties.total_memory / 1e9\n    \n    print(f\"âœ“ Total VRAM: {total_memory_gb:.2f} GB\")\n    print(f\"âœ“ GPU Compute Capability: {gpu_properties.major}.{gpu_properties.minor}\")\n    \n    # Check current memory usage\n    allocated_memory = torch.cuda.memory_allocated(0) / 1e9\n    reserved_memory = torch.cuda.memory_reserved(0) / 1e9\n    \n    print(f\"\\nðŸ“Š Current Memory Status:\")\n    print(f\"   - Allocated: {allocated_memory:.4f} GB\")\n    print(f\"   - Reserved: {reserved_memory:.4f} GB\")\n    print(f\"   - Free: {total_memory_gb - reserved_memory:.2f} GB\")\n    \n    # Verify expected hardware\n    if \"4060\" in gpu_name and 7.0 <= total_memory_gb <= 9.0:\n        print(\"\\nâœ… CONFIRMED: RTX 4060 8GB detected - Ready for training!\")\n    else:\n        print(f\"\\nâš ï¸  WARNING: Expected RTX 4060 8GB, but detected {gpu_name}\")\n        print(f\"   This may affect batch size and training configuration.\")\n    \nelse:\n    print(\"\\nâŒ ERROR: CUDA not available!\")\n    print(\"   Please check:\")\n    print(\"   1. NVIDIA GPU drivers installed\")\n    print(\"   2. CUDA toolkit installed\")\n    print(\"   3. PyTorch installed with CUDA support\")\n    print(\"\\n   Install PyTorch with CUDA:\")\n    print(\"   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n\nprint(\"\\n\" + \"=\" * 70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. CrossViT Model Loading Test\n\n**Objective:** Verify that CrossViT-Tiny can be loaded and run on the GPU"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 70)\nprint(\"CROSSVIT MODEL LOADING TEST\")\nprint(\"=\" * 70)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"\\nâœ“ Using device: {device}\")\n\ntry:\n    # Load CrossViT-Tiny model\n    print(\"\\nðŸ“¥ Loading CrossViT-Tiny from timm library...\")\n    model = timm.create_model('crossvit_tiny_240', pretrained=True, num_classes=4)\n    model = model.to(device)\n    model.eval()\n    \n    print(f\"âœ… Model loaded successfully!\")\n    \n    # Count parameters\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    \n    print(f\"\\nðŸ“Š Model Statistics:\")\n    print(f\"   - Total parameters: {total_params:,}\")\n    print(f\"   - Trainable parameters: {trainable_params:,}\")\n    print(f\"   - Model size: ~{total_params * 4 / 1e6:.2f} MB (FP32)\")\n    \n    # Test forward pass\n    print(\"\\nðŸ§ª Testing forward pass with dummy input...\")\n    dummy_input = torch.randn(1, 3, 240, 240).to(device)\n    \n    with torch.no_grad():\n        output = model(dummy_input)\n    \n    print(f\"âœ… Forward pass successful!\")\n    print(f\"   - Input shape: {dummy_input.shape}\")\n    print(f\"   - Output shape: {output.shape}\")\n    print(f\"   - Expected output shape: torch.Size([1, 4]) for 4 classes\")\n    \n    if output.shape == torch.Size([1, 4]):\n        print(\"\\nâœ… Model configuration CORRECT for COVID-19 4-class classification!\")\n    else:\n        print(f\"\\nâš ï¸  WARNING: Output shape {output.shape} doesn't match expected [1, 4]\")\n    \n    # Check memory usage after loading model\n    if torch.cuda.is_available():\n        model_memory = torch.cuda.memory_allocated(0) / 1e9\n        print(f\"\\nðŸ“Š GPU Memory after model loading: {model_memory:.4f} GB\")\n        print(f\"   - Estimated memory for batch_size=8: ~{model_memory * 8:.2f} GB\")\n        \n        if model_memory * 8 < 7.5:  # Safe threshold for 8GB VRAM\n            print(\"   âœ… Should fit comfortably in 8GB VRAM with batch_size=8\")\n        else:\n            print(\"   âš ï¸  May need smaller batch size or gradient accumulation\")\n    \n    # Clean up\n    del model, dummy_input, output\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    \n    print(\"\\nâœ… CrossViT model test PASSED!\")\n    \nexcept Exception as e:\n    print(f\"\\nâŒ ERROR loading CrossViT model: {e}\")\n    print(\"\\nTroubleshooting:\")\n    print(\"1. Ensure timm is installed: pip install timm\")\n    print(\"2. Check internet connection (for pretrained weights)\")\n    print(\"3. Verify sufficient disk space for model download\")\n\nprint(\"\\n\" + \"=\" * 70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Dataset Path Verification\n\n**Expected:** COVID-19 Radiography Database with 21,165 images across 4 classes"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 70)\nprint(\"DATASET PATH VERIFICATION\")\nprint(\"=\" * 70)\n\n# Define expected dataset structure\nDATA_ROOT = Path(\"../data/raw/COVID-19_Radiography_Dataset\")\n\n# Alternative paths to check\nalternative_paths = [\n    Path(\"../data/raw/COVID-19_Radiography_Dataset\"),\n    Path(\"./data/raw/COVID-19_Radiography_Dataset\"),\n    Path(\"D:/Users/USER/Documents/Visual_Studio_Code/FYP_Code/data/raw/COVID-19_Radiography_Dataset\"),\n]\n\n# Expected classes and approximate counts\nEXPECTED_CLASSES = {\n    \"COVID\": 3616,\n    \"Normal\": 10192,\n    \"Lung_Opacity\": 6012,\n    \"Viral Pneumonia\": 1345\n}\n\ndataset_found = False\ndataset_path = None\n\n# Try to find the dataset\nprint(\"\\nðŸ” Searching for dataset...\")\nfor path in alternative_paths:\n    if path.exists():\n        print(f\"âœ… Found dataset at: {path.absolute()}\")\n        dataset_path = path\n        dataset_found = True\n        break\n    else:\n        print(f\"   âŒ Not found: {path}\")\n\nif dataset_found:\n    print(f\"\\nðŸ“‚ Dataset Location: {dataset_path.absolute()}\")\n    \n    # Check for class folders\n    print(f\"\\nðŸ“Š Class Distribution:\")\n    print(\"-\" * 70)\n    \n    total_images = 0\n    for class_name, expected_count in EXPECTED_CLASSES.items():\n        class_path = dataset_path / class_name / \"images\"\n        \n        if class_path.exists():\n            image_files = list(class_path.glob(\"*.png\"))\n            actual_count = len(image_files)\n            total_images += actual_count\n            \n            # Check if count matches expected\n            match_status = \"âœ…\" if abs(actual_count - expected_count) < 100 else \"âš ï¸ \"\n            \n            print(f\"{match_status} {class_name:20s}: {actual_count:5d} images (expected ~{expected_count})\")\n            \n            # Show sample image path\n            if image_files:\n                print(f\"   Sample: {image_files[0].name}\")\n        else:\n            print(f\"âŒ {class_name:20s}: Folder not found at {class_path}\")\n    \n    print(\"-\" * 70)\n    print(f\"   Total Images: {total_images} (expected ~21,165)\")\n    \n    if 20000 <= total_images <= 22000:\n        print(\"\\nâœ… Dataset verification PASSED!\")\n        print(f\"âœ… Dataset ready for loading in subsequent notebooks\")\n    else:\n        print(f\"\\nâš ï¸  WARNING: Total image count {total_images} differs from expected ~21,165\")\n        print(\"   Please verify dataset integrity\")\n    \n    # Test loading a single image\n    print(\"\\nðŸ§ª Testing image loading...\")\n    try:\n        # Find first image\n        for class_name in EXPECTED_CLASSES.keys():\n            class_path = dataset_path / class_name / \"images\"\n            if class_path.exists():\n                image_files = list(class_path.glob(\"*.png\"))\n                if image_files:\n                    test_image_path = image_files[0]\n                    \n                    # Load with OpenCV\n                    img_cv = cv2.imread(str(test_image_path), cv2.IMREAD_GRAYSCALE)\n                    \n                    # Load with PIL\n                    img_pil = Image.open(test_image_path)\n                    \n                    print(f\"âœ… Successfully loaded: {test_image_path.name}\")\n                    print(f\"   - OpenCV shape: {img_cv.shape}\")\n                    print(f\"   - PIL size: {img_pil.size}\")\n                    print(f\"   - PIL mode: {img_pil.mode}\")\n                    \n                    break\n    except Exception as e:\n        print(f\"âŒ Error loading test image: {e}\")\n    \nelse:\n    print(\"\\nâŒ ERROR: Dataset not found!\")\n    print(\"\\nðŸ“‹ Setup Instructions:\")\n    print(\"1. Download COVID-19 Radiography Database from Kaggle:\")\n    print(\"   https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database\")\n    print(\"\\n2. Extract to: FYP_Code/data/raw/COVID-19_Radiography_Dataset/\")\n    print(\"\\n3. Expected structure:\")\n    print(\"   data/raw/COVID-19_Radiography_Dataset/\")\n    print(\"   â”œâ”€â”€ COVID/images/\")\n    print(\"   â”œâ”€â”€ Normal/images/\")\n    print(\"   â”œâ”€â”€ Lung_Opacity/images/\")\n    print(\"   â””â”€â”€ Viral Pneumonia/images/\")\n\nprint(\"\\n\" + \"=\" * 70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Project Configuration (Single Source of Truth)\n\nAll subsequent notebooks should import this configuration for consistency."
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Environment Verification Summary\n\n### Checklist Status\n\nRun this notebook and verify all checks pass before proceeding to data loading:\n\n- [ ] âœ… Random seeds set (seed=42)\n- [ ] âœ… All dependencies imported successfully\n- [ ] âœ… GPU detected (RTX 4060 8GB VRAM)\n- [ ] âœ… CUDA available and compatible\n- [ ] âœ… CrossViT-Tiny model loads correctly\n- [ ] âœ… Forward pass successful (output shape: [1, 4])\n- [ ] âœ… Dataset found at expected path\n- [ ] âœ… All 4 class folders verified (~21,165 images)\n- [ ] âœ… Sample images load successfully\n- [ ] âœ… Project configuration created\n- [ ] âœ… Memory monitoring utilities ready\n\n---\n\n### Next Steps\n\nOnce all checks pass above:\n\n1. **Next Notebook:** `01_data_loading.ipynb`\n   - Load all 21,165 images\n   - Create train/val/test splits (80/10/10)\n   - Save image paths to CSV for efficient loading\n   - Verify class distribution\n\n2. **Subsequent Pipeline:**\n   ```\n   02_data_cleaning.ipynb    â†’ CLAHE enhancement, validation\n   03_eda.ipynb              â†’ Statistical analysis, visualizations\n   04_data_augmentation.ipynb â†’ Test augmentation strategies\n   05_baseline_models.ipynb   â†’ Train 5 baseline models\n   06_crossvit_training.ipynb â†’ Main model training\n   07_results_analysis.ipynb  â†’ Statistical tests, hypothesis validation\n   08_ablation_studies.ipynb  â†’ Test H2, H3, H4 hypotheses\n   ```\n\n---\n\n### Troubleshooting\n\n**If GPU not detected:**\n- Check NVIDIA drivers: `nvidia-smi`\n- Reinstall PyTorch with CUDA: `pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118`\n\n**If CrossViT fails to load:**\n- Check internet connection (downloads pretrained weights)\n- Install timm: `pip install timm`\n- Verify disk space for model cache (~100MB)\n\n**If dataset not found:**\n- Download from: https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database\n- Extract to: `data/raw/COVID-19_Radiography_Dataset/`\n\n---\n\n**âœ… Environment setup complete! Ready to begin FYP implementation.**",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def print_gpu_memory(prefix=\"\"):\n    \"\"\"Print current GPU memory usage.\"\"\"\n    if torch.cuda.is_available():\n        allocated = torch.cuda.memory_allocated(0) / 1e9\n        reserved = torch.cuda.memory_reserved(0) / 1e9\n        total = torch.cuda.get_device_properties(0).total_memory / 1e9\n        free = total - reserved\n        \n        print(f\"{prefix}GPU Memory: Allocated={allocated:.3f}GB | Reserved={reserved:.3f}GB | Free={free:.3f}GB\")\n    else:\n        print(f\"{prefix}GPU not available\")\n\n\ndef clear_memory():\n    \"\"\"Clear GPU cache and run garbage collection.\"\"\"\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        torch.cuda.synchronize()\n    import gc\n    gc.collect()\n\n\nclass GPUMemoryMonitor:\n    \"\"\"Context manager for monitoring GPU memory during operations.\"\"\"\n    \n    def __init__(self, operation_name=\"Operation\"):\n        self.operation_name = operation_name\n        self.start_memory = 0\n        \n    def __enter__(self):\n        clear_memory()\n        if torch.cuda.is_available():\n            self.start_memory = torch.cuda.memory_allocated(0) / 1e9\n        print(f\"\\n{'='*70}\")\n        print(f\"Starting: {self.operation_name}\")\n        print_gpu_memory(\"  Before: \")\n        return self\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if torch.cuda.is_available():\n            end_memory = torch.cuda.memory_allocated(0) / 1e9\n            delta = end_memory - self.start_memory\n            print_gpu_memory(\"  After:  \")\n            print(f\"  Memory change: {delta:+.3f}GB\")\n        print(f\"Completed: {self.operation_name}\")\n        print(f\"{'='*70}\\n\")\n\n\n# Test the utilities\nprint(\"=\" * 70)\nprint(\"MEMORY MONITORING UTILITIES\")\nprint(\"=\" * 70)\n\nprint(\"\\nâœ“ GPU memory utilities loaded:\")\nprint(\"  - print_gpu_memory(prefix): Print current memory usage\")\nprint(\"  - clear_memory(): Clear GPU cache\")\nprint(\"  - GPUMemoryMonitor(name): Context manager for memory tracking\")\n\nprint(\"\\nðŸ§ª Testing memory monitor...\")\nwith GPUMemoryMonitor(\"Test Operation\"):\n    # Create a small tensor to demonstrate\n    if torch.cuda.is_available():\n        test_tensor = torch.randn(1000, 1000).to(CONFIG['device'])\n        del test_tensor\n\nprint(\"âœ… Memory monitoring utilities ready!\")\nprint(\"=\" * 70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Memory Monitoring Utilities\n\nHelper functions for tracking GPU memory during training.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# PROJECT CONFIGURATION - Single Source of Truth\n# ============================================================================\n\nCONFIG = {\n    # Reproducibility\n    'seed': 42,\n    \n    # Hardware\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n    \n    # Data paths\n    'data_root': Path('../data/raw/COVID-19_Radiography_Dataset'),\n    'processed_data_dir': Path('../data/processed'),\n    'output_dir': Path('../results'),\n    'models_dir': Path('../models'),\n    \n    # Dataset specifications\n    'image_size': 240,  # CrossViT-Tiny requirement\n    'num_classes': 4,\n    'class_names': ['COVID', 'Normal', 'Lung_Opacity', 'Viral Pneumonia'],\n    'class_weights': [1.47, 0.52, 0.88, 3.95],  # For class imbalance\n    \n    # Data split\n    'train_ratio': 0.8,\n    'val_ratio': 0.1,\n    'test_ratio': 0.1,\n    \n    # CLAHE parameters (for preprocessing)\n    'clahe_clip_limit': 2.0,\n    'clahe_tile_grid_size': (8, 8),\n    \n    # ImageNet normalization (required for pretrained models)\n    'mean': [0.485, 0.456, 0.406],\n    'std': [0.229, 0.224, 0.225],\n    \n    # Training hyperparameters (memory-safe for RTX 4060 8GB)\n    'batch_size': 8,\n    'gradient_accumulation_steps': 4,  # Effective batch size = 32\n    'num_workers': 4,\n    'pin_memory': True,\n    'persistent_workers': True,\n    \n    # Optimizer settings\n    'learning_rate': 5e-5,\n    'weight_decay': 0.05,\n    'max_epochs': 50,\n    'early_stopping_patience': 15,\n    \n    # Mixed precision training\n    'use_mixed_precision': True,\n    \n    # Logging\n    'log_interval': 50,  # Print every 50 batches\n    'save_interval': 5,  # Save checkpoint every 5 epochs\n}\n\n# Create necessary directories\nCONFIG['processed_data_dir'].mkdir(parents=True, exist_ok=True)\nCONFIG['output_dir'].mkdir(parents=True, exist_ok=True)\nCONFIG['models_dir'].mkdir(parents=True, exist_ok=True)\n\nprint(\"=\" * 70)\nprint(\"PROJECT CONFIGURATION\")\nprint(\"=\" * 70)\nprint(f\"\\nâœ“ Device: {CONFIG['device']}\")\nprint(f\"âœ“ Batch size: {CONFIG['batch_size']} (effective: {CONFIG['batch_size'] * CONFIG['gradient_accumulation_steps']})\")\nprint(f\"âœ“ Image size: {CONFIG['image_size']}Ã—{CONFIG['image_size']}\")\nprint(f\"âœ“ Number of classes: {CONFIG['num_classes']}\")\nprint(f\"âœ“ Learning rate: {CONFIG['learning_rate']}\")\nprint(f\"âœ“ Max epochs: {CONFIG['max_epochs']}\")\nprint(f\"âœ“ Mixed precision: {CONFIG['use_mixed_precision']}\")\nprint(\"\\nâœ… Configuration ready!\")\nprint(\"=\" * 70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}