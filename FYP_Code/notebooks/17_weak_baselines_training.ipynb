{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17 - VGG-16 & MobileNetV2 Training (Weak Baselines)\n",
    "\n",
    "**Author:** Tan Ming Kai (24PMR12003)  \n",
    "**Date:** 2025-11-26  \n",
    "**Purpose:** Train weak baseline models (VGG-16, MobileNetV2) with 5 random seeds\n",
    "\n",
    "**Hardware:** NVIDIA RTX 6000 Ada (24GB VRAM)\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "1. Train VGG-16 with seeds: 42, 123, 456, 789, 101112\n",
    "2. Train MobileNetV2 with seeds: 42, 123, 456, 789, 101112\n",
    "3. Log all runs to MLflow\n",
    "4. Calculate mean ± std accuracy\n",
    "5. Compare against other baselines in Phase 3\n",
    "\n",
    "---\n",
    "\n",
    "## Optimizations for 24GB VRAM\n",
    "- **Batch size: 64** (vs 8 on 8GB VRAM)\n",
    "- **Gradient accumulation: 1** (not needed with large batch)\n",
    "- **Num workers: 8** (faster data loading)\n",
    "- **Mixed precision: True** (for speed)\n",
    "\n",
    "**Estimated training time:**\n",
    "- VGG-16: ~15 min/seed × 5 = 75 min\n",
    "- MobileNetV2: ~8 min/seed × 5 = 40 min\n",
    "- **Total: ~2 hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os, sys, random, time, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.pytorch\n",
    "    MLFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MLFLOW_AVAILABLE = False\n",
    "    print(\"[WARNING] MLflow not available\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(f\"[OK] PyTorch {torch.__version__} | CUDA: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardware verification\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.2f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration - MATCHED WITH OTHER TRAINING NOTEBOOKS\nCSV_DIR = Path(\"../data/processed\")\nMODELS_DIR = Path(\"../experiments/phase2_models\")\nRESULTS_DIR = Path(\"../experiments/phase2_results\")\nMODELS_DIR.mkdir(parents=True, exist_ok=True)\nRESULTS_DIR.mkdir(parents=True, exist_ok=True)\n\nCONFIG = {\n    'device': device,\n    'num_classes': 4,\n    'image_size': 224,\n    'class_names': ['COVID', 'Normal', 'Lung_Opacity', 'Viral Pneumonia'],\n    'class_weights': [1.47, 0.52, 0.88, 3.95],\n    \n    # OPTIMIZED FOR 24GB+ VRAM (RTX 6000 Ada)\n    'batch_size': 64,\n    'num_workers': 8,\n    \n    # Training hyperparameters - MATCHED WITH OTHER MODELS\n    'learning_rate': 1e-4,      # Same as ResNet, DenseNet, EfficientNet\n    'weight_decay': 1e-4,       # Same as other models (was 0.05)\n    'max_epochs': 30,           # Same as other models (was 50)\n    'early_stopping_patience': 10,  # Same as other models (was 15)\n    \n    # Normalization (ImageNet)\n    'mean': [0.485, 0.456, 0.406],\n    'std': [0.229, 0.224, 0.225],\n    \n    # Mixed precision for speed\n    'mixed_precision': True,\n    \n    # Seeds - same as all other models\n    'seeds': [42, 123, 456, 789, 101112],\n}\n\nprint(f\"Configuration matched with other training notebooks:\")\nprint(f\"  Batch size: {CONFIG['batch_size']}\")\nprint(f\"  Learning rate: {CONFIG['learning_rate']}\")\nprint(f\"  Weight decay: {CONFIG['weight_decay']}\")\nprint(f\"  Max epochs: {CONFIG['max_epochs']}\")\nprint(f\"  Early stopping: {CONFIG['early_stopping_patience']}\")\nprint(f\"  Seeds: {CONFIG['seeds']}\")\nprint(f\"  Models dir: {MODELS_DIR}\")\nprint(f\"  Results dir: {RESULTS_DIR}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow setup\n",
    "if MLFLOW_AVAILABLE:\n",
    "    mlflow.set_experiment(\"crossvit-covid19-classification\")\n",
    "    mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "    print(\"[OK] MLflow configured\")\n",
    "else:\n",
    "    print(\"[WARNING] MLflow not available - results will not be logged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load data - Use train.csv/val.csv/test.csv (raw image paths, not processed)\n# These have 'image_path' column pointing to raw images\n# We'll apply CLAHE on-the-fly in the Dataset class\n\ntrain_df = pd.read_csv(CSV_DIR / \"train.csv\")\nval_df = pd.read_csv(CSV_DIR / \"val.csv\")\ntest_df = pd.read_csv(CSV_DIR / \"test.csv\")\nprint(f\"Train: {len(train_df):,} | Val: {len(val_df):,} | Test: {len(test_df):,}\")\n\n# Verify paths exist\nsample_path = train_df['image_path'].iloc[0]\nprint(f\"\\nSample path: {sample_path}\")\nprint(f\"Path exists: {Path(sample_path).exists()}\")\n\n# Verify class distribution\nprint(\"\\nClass distribution (train):\")\nprint(train_df['label'].value_counts().sort_index())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Dataset class with on-the-fly CLAHE preprocessing\nclass COVID19Dataset(Dataset):\n    \"\"\"\n    Dataset that loads raw images and applies CLAHE preprocessing on-the-fly.\n    \n    Preprocessing:\n    1. Load image (grayscale or BGR)\n    2. Convert to grayscale if needed\n    3. Apply CLAHE (clip_limit=2.0, tile_grid_size=(8,8))\n    4. Convert to RGB (3 channels)\n    5. Apply torchvision transforms\n    \"\"\"\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe.reset_index(drop=True)\n        self.transform = transform\n        self.image_paths = dataframe['image_path'].values  # Use 'image_path' column\n        self.labels = dataframe['label'].values\n        \n        # CLAHE parameters (must match existing preprocessing)\n        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n\n        # Verify first path exists\n        if len(self.image_paths) > 0:\n            first_path = Path(self.image_paths[0])\n            if not first_path.exists():\n                print(f\"[WARNING] First image path does not exist: {first_path}\")\n            else:\n                print(f\"[OK] Path verification passed: {first_path.name}\")\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        \n        # Load image\n        image = cv2.imread(img_path)\n        if image is None:\n            raise FileNotFoundError(f\"Could not load image: {img_path}\")\n        \n        # Convert to grayscale for CLAHE\n        if len(image.shape) == 3:\n            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        else:\n            gray = image\n        \n        # Apply CLAHE\n        enhanced = self.clahe.apply(gray)\n        \n        # Convert to RGB (3 channels for pretrained models)\n        rgb_image = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2RGB)\n        \n        # Convert to PIL Image for torchvision transforms\n        image = Image.fromarray(rgb_image)\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        label = torch.tensor(self.labels[idx], dtype=torch.long)\n        return image, label\n\nprint(\"[OK] Dataset class defined with on-the-fly CLAHE preprocessing\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms (MUST MATCH EXISTING PREPROCESSING)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=CONFIG['mean'], std=CONFIG['std'])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=CONFIG['mean'], std=CONFIG['std'])\n",
    "])\n",
    "\n",
    "print(\"[OK] Transforms defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device, scaler=None, epoch=0):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(loader, desc=f\"Epoch {epoch+1} [Train]\")\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': running_loss / (batch_idx + 1), 'acc': 100. * correct / total})\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device, desc=\"Val\"):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=f\"[{desc}]\"):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total, np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "print(\"[OK] Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Single seed training function - MATCHED WITH OTHER NOTEBOOKS\ndef train_model_single_seed(model_name, model_fn, seed, config):\n    \"\"\"\n    Train a model with a single seed.\n    \n    Args:\n        model_name: str, e.g., 'VGG-16' or 'MobileNetV2'\n        model_fn: callable that returns a model\n        seed: int, random seed\n        config: dict, configuration\n    \"\"\"\n    print(f\"\\n{'='*70}\\nTRAINING {model_name.upper()} WITH SEED {seed}\\n{'='*70}\")\n    \n    set_seed(seed)\n    \n    # Create dataloaders\n    train_dataset = COVID19Dataset(train_df, transform=train_transform)\n    val_dataset = COVID19Dataset(val_df, transform=val_transform)\n    test_dataset = COVID19Dataset(test_df, transform=val_transform)\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config['batch_size'],\n        shuffle=True,\n        num_workers=config['num_workers'],\n        pin_memory=True,\n        persistent_workers=True if config['num_workers'] > 0 else False\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=config['batch_size'],\n        shuffle=False,\n        num_workers=config['num_workers'],\n        pin_memory=True,\n        persistent_workers=True if config['num_workers'] > 0 else False\n    )\n    \n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=config['batch_size'],\n        shuffle=False,\n        num_workers=config['num_workers'],\n        pin_memory=True,\n        persistent_workers=True if config['num_workers'] > 0 else False\n    )\n    \n    # Load model\n    model = model_fn()\n    model = model.to(device)\n    \n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f\"[OK] {model_name} loaded: {total_params:,} parameters ({trainable_params:,} trainable)\")\n    \n    # Loss, optimizer, scheduler - MATCHED WITH OTHER MODELS\n    class_weights = torch.tensor(config['class_weights'], dtype=torch.float32).to(device)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    \n    # Use Adam (not AdamW) - same as ResNet, DenseNet, EfficientNet\n    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n    \n    # Use ReduceLROnPlateau - same as other models\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n    \n    scaler = torch.cuda.amp.GradScaler() if config['mixed_precision'] else None\n    \n    # MLflow\n    if MLFLOW_AVAILABLE:\n        mlflow.start_run(run_name=f\"{model_name.lower().replace('-', '')}-seed-{seed}\")\n        mlflow.log_param(\"model\", model_name)\n        mlflow.log_param(\"random_seed\", seed)\n        mlflow.log_param(\"batch_size\", config['batch_size'])\n        mlflow.log_param(\"learning_rate\", config['learning_rate'])\n        mlflow.log_param(\"weight_decay\", config['weight_decay'])\n        mlflow.log_param(\"optimizer\", \"Adam\")\n        mlflow.log_param(\"scheduler\", \"ReduceLROnPlateau\")\n        mlflow.log_param(\"image_size\", config['image_size'])\n        mlflow.set_tag(\"phase\", \"Phase 2 - Weak Baselines\")\n        mlflow.set_tag(\"hardware\", \"RTX 6000 Ada\")\n    \n    # Training loop\n    best_val_loss = float('inf')\n    patience_counter = 0\n    best_model_path = MODELS_DIR / f\"{model_name.lower().replace('-', '')}_seed{seed}.pth\"\n    \n    start_time = time.time()\n    \n    for epoch in range(config['max_epochs']):\n        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, scaler, epoch)\n        val_loss, val_acc, _, _ = validate(model, val_loader, criterion, device)\n        \n        # ReduceLROnPlateau needs val_loss\n        scheduler.step(val_loss)\n        \n        if MLFLOW_AVAILABLE:\n            mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n            mlflow.log_metric(\"train_acc\", train_acc, step=epoch)\n            mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n            mlflow.log_metric(\"val_acc\", val_acc, step=epoch)\n            mlflow.log_metric(\"learning_rate\", optimizer.param_groups[0]['lr'], step=epoch)\n        \n        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f} Acc={train_acc:.2f}% | Val Loss={val_loss:.4f} Acc={val_acc:.2f}%\")\n        \n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            patience_counter = 0\n            torch.save(model.state_dict(), best_model_path)\n            print(f\"[OK] Best model saved! ({best_model_path.name})\")\n        else:\n            patience_counter += 1\n            if patience_counter >= config['early_stopping_patience']:\n                print(f\"[STOP] Early stopping at epoch {epoch+1}\")\n                break\n    \n    training_time = time.time() - start_time\n    \n    # Test evaluation\n    model.load_state_dict(torch.load(best_model_path, weights_only=True))\n    test_loss, test_acc, test_preds, test_labels = validate(model, test_loader, criterion, device, desc=\"Test\")\n    \n    # Confusion matrix\n    cm = confusion_matrix(test_labels, test_preds)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=config['class_names'], yticklabels=config['class_names'])\n    plt.ylabel('True')\n    plt.xlabel('Predicted')\n    plt.title(f\"{model_name} Confusion Matrix (Seed {seed})\")\n    cm_path = RESULTS_DIR / f\"{model_name.lower().replace('-', '')}_cm_seed{seed}.png\"\n    plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n    plt.close()\n    \n    # Classification report\n    report = classification_report(test_labels, test_preds, target_names=config['class_names'], output_dict=True)\n    \n    if MLFLOW_AVAILABLE:\n        mlflow.log_metric(\"test_loss\", test_loss)\n        mlflow.log_metric(\"test_accuracy\", test_acc)\n        mlflow.log_metric(\"training_time_minutes\", training_time / 60)\n        mlflow.log_artifact(str(cm_path))\n        \n        # Log per-class metrics\n        for class_name in config['class_names']:\n            mlflow.log_metric(f\"{class_name}_precision\", report[class_name]['precision'])\n            mlflow.log_metric(f\"{class_name}_recall\", report[class_name]['recall'])\n            mlflow.log_metric(f\"{class_name}_f1\", report[class_name]['f1-score'])\n        \n        mlflow.end_run()\n    \n    print(f\"[OK] Seed {seed} complete: Test Acc = {test_acc:.2f}% | Time = {training_time/60:.1f} min\")\n    print(f\"[OK] Model saved to: {best_model_path}\")\n    \n    # Clean up GPU memory\n    del model\n    torch.cuda.empty_cache()\n    \n    return {\n        'model': model_name,\n        'seed': seed,\n        'test_acc': test_acc,\n        'test_loss': test_loss,\n        'training_time_min': training_time / 60,\n        'best_val_loss': best_val_loss\n    }\n\nprint(\"[OK] Single seed training function defined (matched with other notebooks)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# VGG-16 Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16 model definition\n",
    "def create_vgg16():\n",
    "    \"\"\"\n",
    "    Create VGG-16 model with pretrained ImageNet weights.\n",
    "    Replace final classifier layer for 4-class COVID-19 classification.\n",
    "    \"\"\"\n",
    "    model = models.vgg16(weights='IMAGENET1K_V1')\n",
    "    \n",
    "    # Replace final layer: 4096 -> 4 classes\n",
    "    model.classifier[6] = nn.Linear(4096, 4)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Test model creation\n",
    "test_model = create_vgg16()\n",
    "print(f\"[OK] VGG-16 created: {sum(p.numel() for p in test_model.parameters()):,} parameters\")\n",
    "del test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train VGG-16 with all seeds\n",
    "print(f\"\\n{'='*70}\\nSTARTING MULTI-SEED VGG-16 TRAINING\\n{'='*70}\")\n",
    "print(f\"Seeds: {CONFIG['seeds']}\\n\")\n",
    "\n",
    "vgg16_results = []\n",
    "for seed in CONFIG['seeds']:\n",
    "    try:\n",
    "        result = train_model_single_seed('VGG-16', create_vgg16, seed, CONFIG)\n",
    "        vgg16_results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error with VGG-16 seed {seed}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*70}\\nVGG-16 ALL SEEDS COMPLETED\\n{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16 Statistical analysis\n",
    "vgg16_accuracies = [r['test_acc'] for r in vgg16_results]\n",
    "vgg16_mean_acc = np.mean(vgg16_accuracies)\n",
    "vgg16_std_acc = np.std(vgg16_accuracies, ddof=1)\n",
    "\n",
    "print(f\"\\n[STATS] VGG-16 Results (5 seeds):\")\n",
    "print(f\"   Mean ± Std: {vgg16_mean_acc:.2f}% ± {vgg16_std_acc:.2f}%\")\n",
    "print(f\"   Range: [{np.min(vgg16_accuracies):.2f}%, {np.max(vgg16_accuracies):.2f}%]\")\n",
    "print(f\"   Median: {np.median(vgg16_accuracies):.2f}%\")\n",
    "\n",
    "# Save results\n",
    "vgg16_df = pd.DataFrame(vgg16_results)\n",
    "vgg16_results_path = RESULTS_DIR / \"vgg16_results.csv\"\n",
    "vgg16_df.to_csv(vgg16_results_path, index=False)\n",
    "print(f\"\\n[OK] Results saved to {vgg16_results_path}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(vgg16_df.to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# MobileNetV2 Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2 model definition\n",
    "def create_mobilenetv2():\n",
    "    \"\"\"\n",
    "    Create MobileNetV2 model with pretrained ImageNet weights.\n",
    "    Replace final classifier layer for 4-class COVID-19 classification.\n",
    "    \"\"\"\n",
    "    model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "    \n",
    "    # Replace final layer: 1280 -> 4 classes\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, 4)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Test model creation\n",
    "test_model = create_mobilenetv2()\n",
    "print(f\"[OK] MobileNetV2 created: {sum(p.numel() for p in test_model.parameters()):,} parameters\")\n",
    "del test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MobileNetV2 with all seeds\n",
    "print(f\"\\n{'='*70}\\nSTARTING MULTI-SEED MOBILENETV2 TRAINING\\n{'='*70}\")\n",
    "print(f\"Seeds: {CONFIG['seeds']}\\n\")\n",
    "\n",
    "mobilenetv2_results = []\n",
    "for seed in CONFIG['seeds']:\n",
    "    try:\n",
    "        result = train_model_single_seed('MobileNetV2', create_mobilenetv2, seed, CONFIG)\n",
    "        mobilenetv2_results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error with MobileNetV2 seed {seed}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "print(f\"\\n{'='*70}\\nMOBILENETV2 ALL SEEDS COMPLETED\\n{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV2 Statistical analysis\n",
    "mobilenetv2_accuracies = [r['test_acc'] for r in mobilenetv2_results]\n",
    "mobilenetv2_mean_acc = np.mean(mobilenetv2_accuracies)\n",
    "mobilenetv2_std_acc = np.std(mobilenetv2_accuracies, ddof=1)\n",
    "\n",
    "print(f\"\\n[STATS] MobileNetV2 Results (5 seeds):\")\n",
    "print(f\"   Mean ± Std: {mobilenetv2_mean_acc:.2f}% ± {mobilenetv2_std_acc:.2f}%\")\n",
    "print(f\"   Range: [{np.min(mobilenetv2_accuracies):.2f}%, {np.max(mobilenetv2_accuracies):.2f}%]\")\n",
    "print(f\"   Median: {np.median(mobilenetv2_accuracies):.2f}%\")\n",
    "\n",
    "# Save results\n",
    "mobilenetv2_df = pd.DataFrame(mobilenetv2_results)\n",
    "mobilenetv2_results_path = RESULTS_DIR / \"mobilenetv2_results.csv\"\n",
    "mobilenetv2_df.to_csv(mobilenetv2_results_path, index=False)\n",
    "print(f\"\\n[OK] Results saved to {mobilenetv2_results_path}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(mobilenetv2_df.to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary Comparison\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined summary\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FINAL SUMMARY: VGG-16 vs MobileNetV2\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "summary_data = [\n",
    "    {\n",
    "        'Model': 'VGG-16',\n",
    "        'Mean Acc': f\"{vgg16_mean_acc:.2f}%\",\n",
    "        'Std': f\"{vgg16_std_acc:.2f}%\",\n",
    "        'Min': f\"{np.min(vgg16_accuracies):.2f}%\",\n",
    "        'Max': f\"{np.max(vgg16_accuracies):.2f}%\",\n",
    "        'Median': f\"{np.median(vgg16_accuracies):.2f}%\"\n",
    "    },\n",
    "    {\n",
    "        'Model': 'MobileNetV2',\n",
    "        'Mean Acc': f\"{mobilenetv2_mean_acc:.2f}%\",\n",
    "        'Std': f\"{mobilenetv2_std_acc:.2f}%\",\n",
    "        'Min': f\"{np.min(mobilenetv2_accuracies):.2f}%\",\n",
    "        'Max': f\"{np.max(mobilenetv2_accuracies):.2f}%\",\n",
    "        'Median': f\"{np.median(mobilenetv2_accuracies):.2f}%\"\n",
    "    }\n",
    "]\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(f\"\\n{'='*70}\")\n",
    "\n",
    "# Save combined summary\n",
    "summary_path = RESULTS_DIR / \"weak_baselines_summary.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"[OK] Summary saved to {summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Box plot comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "data_to_plot = [vgg16_accuracies, mobilenetv2_accuracies]\n",
    "labels = ['VGG-16', 'MobileNetV2']\n",
    "\n",
    "bp = ax.boxplot(data_to_plot, labels=labels, patch_artist=True)\n",
    "\n",
    "# Color the boxes\n",
    "colors = ['lightblue', 'lightgreen']\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "ax.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Weak Baselines Comparison (5 Seeds)', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add mean markers\n",
    "means = [vgg16_mean_acc, mobilenetv2_mean_acc]\n",
    "ax.scatter([1, 2], means, marker='D', s=100, color='red', zorder=3, label='Mean')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "boxplot_path = RESULTS_DIR / \"weak_baselines_boxplot.png\"\n",
    "plt.savefig(boxplot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"[OK] Box plot saved to {boxplot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Training Complete!\n",
    "---\n",
    "\n",
    "**Models saved to:** `experiments/phase2_models/`\n",
    "- vgg16_seed42.pth, vgg16_seed123.pth, vgg16_seed456.pth, vgg16_seed789.pth, vgg16_seed101112.pth\n",
    "- mobilenetv2_seed42.pth, mobilenetv2_seed123.pth, mobilenetv2_seed456.pth, mobilenetv2_seed789.pth, mobilenetv2_seed101112.pth\n",
    "\n",
    "**Results saved to:** `experiments/phase2_results/`\n",
    "- vgg16_results.csv\n",
    "- mobilenetv2_results.csv\n",
    "- weak_baselines_summary.csv\n",
    "- weak_baselines_boxplot.png\n",
    "\n",
    "**Next steps:**\n",
    "1. Compare these results with other baselines (ResNet-50, DenseNet-121, etc.)\n",
    "2. Proceed to Phase 3: Statistical validation (12_statistical_validation.ipynb)\n",
    "3. Calculate 95% confidence intervals\n",
    "4. Perform hypothesis testing (CrossViT vs all baselines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}