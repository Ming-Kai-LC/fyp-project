{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Baseline Model Test (ResNet-50)\n",
    "\n",
    "**Author:** Tan Ming Kai (24PMR12003)  \n",
    "**Date:** 2025-11-11  \n",
    "**Purpose:** Get ONE baseline model working to verify training pipeline\n",
    "\n",
    "**Project:** Multi-Scale Vision Transformer (CrossViT) for COVID-19 Chest X-ray Classification  \n",
    "**Academic Year:** 2025/26\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "1. ‚úÖ Create PyTorch Dataset for loading CLAHE-enhanced images\n",
    "2. ‚úÖ Implement DataLoader with memory-safe settings\n",
    "3. ‚úÖ Load ResNet-50 baseline model\n",
    "4. ‚úÖ Train on small subset (1000 images) first\n",
    "5. ‚úÖ Verify GPU memory usage (<7GB)\n",
    "6. ‚úÖ Train on full dataset\n",
    "7. ‚úÖ Achieve >70% accuracy (confirm pipeline works)\n",
    "8. ‚úÖ Log results to MLflow\n",
    "9. ‚úÖ Save best model checkpoint\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 1: Exploration - Final Step\n",
    "\n",
    "This notebook completes Phase 1 by verifying you can successfully train a deep learning model on the preprocessed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reproducibility Setup & Imports\n",
    "\n",
    "**CRITICAL:** Load reproducibility seeds and required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Baseline Model Test Notebook for CrossViT COVID-19 FYP\n",
    "Author: Tan Ming Kai (24PMR12003)\n",
    "Purpose: Verify training pipeline works with ResNet-50 baseline\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# 1. REPRODUCIBILITY SETUP (ALWAYS FIRST!)\n",
    "# ============================================================================\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"‚úÖ Random seeds set to 42 for reproducibility\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. STANDARD LIBRARY IMPORTS\n",
    "# ============================================================================\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import time\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# 3. DATA SCIENCE LIBRARIES\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# ============================================================================\n",
    "# 4. PYTORCH & DEEP LEARNING\n",
    "# ============================================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# ============================================================================\n",
    "# 5. COMPUTER VISION\n",
    "# ============================================================================\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# ============================================================================\n",
    "# 6. MLFLOW (Experiment Tracking)\n",
    "# ============================================================================\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.pytorch\n",
    "    MLFLOW_AVAILABLE = True\n",
    "    print(\"‚úÖ MLflow available for experiment tracking\")\n",
    "except ImportError:\n",
    "    MLFLOW_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  MLflow not installed. Install with: pip install mlflow\")\n",
    "    print(\"   Continuing without experiment tracking...\")\n",
    "\n",
    "# ============================================================================\n",
    "# 7. SKLEARN (Metrics)\n",
    "# ============================================================================\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hardware Verification\n",
    "\n",
    "Verify GPU is available and check VRAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"HARDWARE VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check CUDA\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if cuda_available else 'cpu')\n",
    "\n",
    "print(f\"\\n‚úì CUDA Available: {cuda_available}\")\n",
    "print(f\"‚úì Using Device: {device}\")\n",
    "\n",
    "if cuda_available:\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    \n",
    "    print(f\"‚úì GPU: {gpu_name}\")\n",
    "    print(f\"‚úì Total VRAM: {total_memory:.2f} GB\")\n",
    "    print(f\"‚úì CUDA Version: {torch.version.cuda}\")\n",
    "    \n",
    "    # Memory monitoring function\n",
    "    def print_gpu_memory(prefix=\"\"):\n",
    "        allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "        reserved = torch.cuda.memory_reserved(0) / 1e9\n",
    "        free = total_memory - reserved\n",
    "        print(f\"{prefix}GPU Memory: Allocated={allocated:.3f}GB | Reserved={reserved:.3f}GB | Free={free:.3f}GB\")\n",
    "    \n",
    "    print_gpu_memory(\"\\n  \")\n",
    "    \n",
    "    if \"4060\" in gpu_name and 7.0 <= total_memory <= 9.0:\n",
    "        print(\"\\n‚úÖ CONFIRMED: RTX 4060 8GB detected - Ready for training!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Different GPU detected: {gpu_name}\")\n",
    "        print(\"   Adjust batch size if needed based on VRAM.\")\n",
    "else:\n",
    "    print(\"\\n‚ùå WARNING: No GPU detected! Training will be VERY slow.\")\n",
    "    print(\"   Please ensure CUDA drivers and PyTorch with CUDA are installed.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "Define all training parameters and paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Paths\nCSV_DIR = Path(\"../data/processed\")\nPROCESSED_IMG_DIR = Path(\"../data/processed/clahe_enhanced\")\nMODELS_DIR = Path(\"../models\")\nRESULTS_DIR = Path(\"../results\")\n\n# Create directories\nMODELS_DIR.mkdir(parents=True, exist_ok=True)\nRESULTS_DIR.mkdir(parents=True, exist_ok=True)\n\n# Training configuration (Memory-safe for RTX 4060 8GB)\nCONFIG = {\n    # Reproducibility\n    'seed': 42,\n    'device': device,\n    \n    # Model\n    'model_name': 'ResNet-50',\n    'num_classes': 4,\n    'pretrained': True,\n    \n    # Data\n    'image_size': 240,\n    'class_names': ['COVID', 'Normal', 'Lung_Opacity', 'Viral Pneumonia'],\n    'class_weights': [1.47, 0.52, 0.88, 3.95],  # From EDA\n    \n    # Training hyperparameters\n    'batch_size': 16,  # Safe for 8GB VRAM\n    'num_workers': 0,  # WINDOWS FIX: Use 0 for Windows (4 for Linux/Mac)\n    'pin_memory': True,\n    'persistent_workers': False,  # WINDOWS FIX: Must be False when num_workers=0\n    \n    # Optimizer\n    'learning_rate': 1e-4,  # ResNet-50 default\n    'weight_decay': 1e-4,\n    'max_epochs': 30,  # Start with fewer epochs for testing\n    'early_stopping_patience': 10,\n    \n    # ImageNet normalization\n    'mean': [0.485, 0.456, 0.406],\n    'std': [0.229, 0.224, 0.225],\n    \n    # Memory management\n    'mixed_precision': True,\n    'memory_check_interval': 50,  # Check GPU memory every N batches\n    \n    # Testing\n    'test_on_subset': True,  # Start with small subset\n    'subset_size': 1000,  # Images per class for quick test\n}\n\nprint(\"=\" * 70)\nprint(\"CONFIGURATION\")\nprint(\"=\" * 70)\nprint(f\"\\n‚úì Model: {CONFIG['model_name']}\")\nprint(f\"‚úì Device: {CONFIG['device']}\")\nprint(f\"‚úì Batch Size: {CONFIG['batch_size']}\")\nprint(f\"‚úì Learning Rate: {CONFIG['learning_rate']}\")\nprint(f\"‚úì Max Epochs: {CONFIG['max_epochs']}\")\nprint(f\"‚úì Image Size: {CONFIG['image_size']}√ó{CONFIG['image_size']}\")\nprint(f\"‚úì Mixed Precision: {CONFIG['mixed_precision']}\")\nprint(f\"\\n‚úì Test on Subset: {CONFIG['test_on_subset']}\")\nif CONFIG['test_on_subset']:\n    print(f\"  ‚Üí Subset Size: {CONFIG['subset_size']} images per split\")\nprint(f\"\\n‚ö†Ô∏è  Windows Mode: num_workers=0 (single-threaded loading)\")\nprint(f\"   This is slower but stable on Windows\")\nprint(\"\\n\" + \"=\" * 70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MLflow Setup\n",
    "\n",
    "Initialize experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"MLFLOW EXPERIMENT TRACKING SETUP\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if MLFLOW_AVAILABLE:\n",
    "    # Set experiment name\n",
    "    mlflow.set_experiment(\"crossvit-covid19-classification\")\n",
    "    \n",
    "    # Set tracking URI (local directory)\n",
    "    mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "    \n",
    "    print(\"\\n‚úÖ MLflow configured:\")\n",
    "    print(f\"   - Experiment: crossvit-covid19-classification\")\n",
    "    print(f\"   - Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "    print(f\"\\nüí° View results: Run 'mlflow ui' in terminal, then open http://localhost:5000\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  MLflow not available. Results will not be logged.\")\n",
    "    print(\"   Install with: pip install mlflow\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Data Splits\n",
    "\n",
    "Load CSV files with paths to preprocessed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"LOADING DATA SPLITS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load processed CSV files\n",
    "train_df = pd.read_csv(CSV_DIR / \"train_processed.csv\")\n",
    "val_df = pd.read_csv(CSV_DIR / \"val_processed.csv\")\n",
    "test_df = pd.read_csv(CSV_DIR / \"test_processed.csv\")\n",
    "\n",
    "print(f\"\\n‚úÖ CSV files loaded:\")\n",
    "print(f\"   - Train: {len(train_df):,} images\")\n",
    "print(f\"   - Val:   {len(val_df):,} images\")\n",
    "print(f\"   - Test:  {len(test_df):,} images\")\n",
    "\n",
    "# Verify processed_path column exists\n",
    "if 'processed_path' in train_df.columns:\n",
    "    print(f\"\\n‚úÖ Using preprocessed images from: processed_path column\")\n",
    "    \n",
    "    # Test loading one image\n",
    "    test_path = train_df.iloc[0]['processed_path']\n",
    "    if Path(test_path).exists():\n",
    "        test_img = cv2.imread(test_path)\n",
    "        print(f\"   ‚úì Sample image loaded successfully: {test_img.shape}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå ERROR: Sample image not found at {test_path}\")\n",
    "        print(f\"   Please verify processed images exist.\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå ERROR: 'processed_path' column not found in CSV\")\n",
    "    print(f\"   Please run 02_data_cleaning.ipynb first.\")\n",
    "\n",
    "print(\"\\nüìä Class Distribution in Training Set:\")\n",
    "class_counts = train_df['class_name'].value_counts()\n",
    "for class_name, count in class_counts.items():\n",
    "    pct = count / len(train_df) * 100\n",
    "    print(f\"   {class_name:20s}: {count:5d} ({pct:5.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create PyTorch Dataset\n",
    "\n",
    "Custom Dataset class for loading CLAHE-enhanced images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COVID19Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for COVID-19 chest X-ray classification.\n",
    "    \n",
    "    Loads CLAHE-enhanced images (240√ó240√ó3 RGB) from preprocessed directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame with 'processed_path' and 'label' columns\n",
    "            transform (callable, optional): Transformations to apply to images\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Extract paths and labels\n",
    "        self.image_paths = self.dataframe['processed_path'].values\n",
    "        self.labels = self.dataframe['label'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Load and return image and label at index idx.\n",
    "        \"\"\"\n",
    "        # Load image (BGR format from cv2)\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "        \n",
    "        # Convert BGR to RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Convert to PIL Image for torchvision transforms\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get label\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "print(\"‚úÖ COVID19Dataset class defined\")\n",
    "print(\"\\nüìù Features:\")\n",
    "print(\"   - Loads CLAHE-enhanced images (240√ó240√ó3)\")\n",
    "print(\"   - Converts BGR ‚Üí RGB\")\n",
    "print(\"   - Applies torchvision transforms\")\n",
    "print(\"   - Returns (image, label) tensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define Data Transforms\n",
    "\n",
    "Create transforms for training and validation.\n",
    "\n",
    "**Important:** No aggressive augmentation yet - just normalization for baseline test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training transforms (minimal augmentation for now)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Only horizontal flip\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=CONFIG['mean'], std=CONFIG['std'])\n",
    "])\n",
    "\n",
    "# Validation/Test transforms (no augmentation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=CONFIG['mean'], std=CONFIG['std'])\n",
    "])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATA TRANSFORMS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n‚úÖ Training transforms:\")\n",
    "print(\"   1. Resize to 240√ó240\")\n",
    "print(\"   2. Random horizontal flip (50%)\")\n",
    "print(\"   3. ToTensor()\")\n",
    "print(\"   4. Normalize (ImageNet stats)\")\n",
    "\n",
    "print(\"\\n‚úÖ Validation/Test transforms:\")\n",
    "print(\"   1. Resize to 240√ó240\")\n",
    "print(\"   2. ToTensor()\")\n",
    "print(\"   3. Normalize (ImageNet stats)\")\n",
    "\n",
    "print(\"\\nüí° Note: Using minimal augmentation for baseline test.\")\n",
    "print(\"   More augmentation will be tested in 05_augmentation_test.ipynb\")\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Datasets and DataLoaders\n",
    "\n",
    "Instantiate Dataset objects and DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CREATING DATASETS AND DATALOADERS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = COVID19Dataset(train_df, transform=train_transform)\n",
    "val_dataset = COVID19Dataset(val_df, transform=val_transform)\n",
    "test_dataset = COVID19Dataset(test_df, transform=val_transform)\n",
    "\n",
    "print(f\"\\n‚úÖ Datasets created:\")\n",
    "print(f\"   - Train: {len(train_dataset):,} images\")\n",
    "print(f\"   - Val:   {len(val_dataset):,} images\")\n",
    "print(f\"   - Test:  {len(test_dataset):,} images\")\n",
    "\n",
    "# Create subset for quick testing (if enabled)\n",
    "if CONFIG['test_on_subset']:\n",
    "    subset_size = CONFIG['subset_size']\n",
    "    \n",
    "    # Random subset\n",
    "    train_indices = np.random.choice(len(train_dataset), min(subset_size, len(train_dataset)), replace=False)\n",
    "    val_indices = np.random.choice(len(val_dataset), min(subset_size//5, len(val_dataset)), replace=False)\n",
    "    test_indices = np.random.choice(len(test_dataset), min(subset_size//5, len(test_dataset)), replace=False)\n",
    "    \n",
    "    train_dataset_use = Subset(train_dataset, train_indices)\n",
    "    val_dataset_use = Subset(val_dataset, val_indices)\n",
    "    test_dataset_use = Subset(test_dataset, test_indices)\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è  Using SUBSET for quick testing:\")\n",
    "    print(f\"   - Train: {len(train_dataset_use):,} images (sampled)\")\n",
    "    print(f\"   - Val:   {len(val_dataset_use):,} images (sampled)\")\n",
    "    print(f\"   - Test:  {len(test_dataset_use):,} images (sampled)\")\n",
    "    print(f\"\\n   üí° To use FULL dataset, set CONFIG['test_on_subset'] = False\")\n",
    "else:\n",
    "    train_dataset_use = train_dataset\n",
    "    val_dataset_use = val_dataset\n",
    "    test_dataset_use = test_dataset\n",
    "    print(f\"\\n‚úÖ Using FULL dataset for training\")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset_use,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=CONFIG['pin_memory'],\n",
    "    persistent_workers=CONFIG['persistent_workers'],\n",
    "    drop_last=True  # Drop incomplete batch\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset_use,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=CONFIG['pin_memory'],\n",
    "    persistent_workers=CONFIG['persistent_workers']\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset_use,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=CONFIG['pin_memory'],\n",
    "    persistent_workers=CONFIG['persistent_workers']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ DataLoaders created:\")\n",
    "print(f\"   - Train batches: {len(train_loader)}\")\n",
    "print(f\"   - Val batches:   {len(val_loader)}\")\n",
    "print(f\"   - Test batches:  {len(test_loader)}\")\n",
    "print(f\"   - Batch size:    {CONFIG['batch_size']}\")\n",
    "print(f\"   - Num workers:   {CONFIG['num_workers']}\")\n",
    "\n",
    "# Test loading one batch\n",
    "print(f\"\\nüß™ Testing DataLoader...\")\n",
    "sample_images, sample_labels = next(iter(train_loader))\n",
    "print(f\"   ‚úì Sample batch shape: {sample_images.shape}\")\n",
    "print(f\"   ‚úì Sample labels shape: {sample_labels.shape}\")\n",
    "print(f\"   ‚úì Image value range: [{sample_images.min():.3f}, {sample_images.max():.3f}]\")\n",
    "print(f\"   ‚úì Unique labels in batch: {sample_labels.unique().tolist()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Load ResNet-50 Model\n",
    "\n",
    "Load pretrained ResNet-50 and modify for 4-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"LOADING RESNET-50 MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load pretrained ResNet-50\n",
    "model = models.resnet50(pretrained=CONFIG['pretrained'])\n",
    "\n",
    "# Modify final layer for 4 classes\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, CONFIG['num_classes'])\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n‚úÖ ResNet-50 loaded successfully\")\n",
    "print(f\"   - Pretrained: {CONFIG['pretrained']}\")\n",
    "print(f\"   - Total parameters: {total_params:,}\")\n",
    "print(f\"   - Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"   - Model size: ~{total_params * 4 / 1e6:.2f} MB (FP32)\")\n",
    "print(f\"   - Device: {device}\")\n",
    "\n",
    "# Test forward pass\n",
    "print(f\"\\nüß™ Testing forward pass...\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(1, 3, CONFIG['image_size'], CONFIG['image_size']).to(device)\n",
    "    test_output = model(test_input)\n",
    "\n",
    "print(f\"   ‚úì Input shape: {test_input.shape}\")\n",
    "print(f\"   ‚úì Output shape: {test_output.shape}\")\n",
    "print(f\"   ‚úì Expected: torch.Size([1, {CONFIG['num_classes']}])\")\n",
    "\n",
    "if test_output.shape == torch.Size([1, CONFIG['num_classes']]):\n",
    "    print(f\"\\n‚úÖ Model configuration CORRECT for 4-class classification!\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå ERROR: Output shape mismatch!\")\n",
    "\n",
    "# Check GPU memory after loading model\n",
    "if cuda_available:\n",
    "    print_gpu_memory(\"\\n  \")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Define Loss Function and Optimizer\n",
    "\n",
    "Use weighted CrossEntropyLoss for class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights for imbalanced dataset\n",
    "class_weights = torch.tensor(CONFIG['class_weights'], dtype=torch.float32).to(device)\n",
    "\n",
    "# Loss function with class weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Mixed precision scaler (if enabled)\n",
    "if CONFIG['mixed_precision'] and cuda_available:\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    print(\"‚úÖ Using mixed precision training (FP16)\")\n",
    "else:\n",
    "    scaler = None\n",
    "    print(\"‚úÖ Using standard precision training (FP32)\")\n",
    "\n",
    "print(\"\\n=\" * 70)\n",
    "print(\"TRAINING SETUP\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n‚úì Loss Function: CrossEntropyLoss (weighted)\")\n",
    "print(f\"   - Class weights: {CONFIG['class_weights']}\")\n",
    "print(f\"\\n‚úì Optimizer: Adam\")\n",
    "print(f\"   - Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"   - Weight decay: {CONFIG['weight_decay']}\")\n",
    "print(f\"\\n‚úì Scheduler: ReduceLROnPlateau\")\n",
    "print(f\"   - Factor: 0.5\")\n",
    "print(f\"   - Patience: 5 epochs\")\n",
    "print(f\"\\n‚úì Mixed Precision: {CONFIG['mixed_precision']}\")\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Training and Validation Functions\n",
    "\n",
    "Define training and validation loops with memory monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device, scaler=None, epoch=0):\n",
    "    \"\"\"\n",
    "    Train for one epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(loader, desc=f\"Epoch {epoch+1} [Train]\")\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "        # Move to device\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        # Forward pass with mixed precision\n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': running_loss / (batch_idx + 1),\n",
    "            'acc': 100. * correct / total\n",
    "        })\n",
    "        \n",
    "        # Memory monitoring\n",
    "        if cuda_available and batch_idx % CONFIG['memory_check_interval'] == 0:\n",
    "            if batch_idx == 0:\n",
    "                print_gpu_memory(\"\\n  \")\n",
    "        \n",
    "        # Clear cache periodically\n",
    "        if cuda_available and batch_idx % 10 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device, desc=\"Val\"):\n",
    "    \"\"\"\n",
    "    Validate model on validation/test set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(loader, desc=f\"[{desc}]\")\n",
    "        \n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Store for metrics\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': running_loss / (progress_bar.n + 1),\n",
    "                'acc': 100. * correct / total\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Training and validation functions defined\")\n",
    "print(\"\\nüìù Features:\")\n",
    "print(\"   - Mixed precision support (FP16)\")\n",
    "print(\"   - GPU memory monitoring\")\n",
    "print(\"   - Progress bars (tqdm)\")\n",
    "print(\"   - Automatic cache clearing\")\n",
    "print(\"   - Returns predictions for metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Training Loop\n",
    "\n",
    "Train the model with early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "# Early stopping\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_model_path = MODELS_DIR / f\"resnet50_best_seed{CONFIG['seed']}.pth\"\n",
    "\n",
    "# Start MLflow run\n",
    "if MLFLOW_AVAILABLE:\n",
    "    run_name = f\"resnet50-baseline-seed-{CONFIG['seed']}\"\n",
    "    if CONFIG['test_on_subset']:\n",
    "        run_name += \"-SUBSET\"\n",
    "    \n",
    "    mlflow.start_run(run_name=run_name)\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model\", CONFIG['model_name'])\n",
    "    mlflow.log_param(\"random_seed\", CONFIG['seed'])\n",
    "    mlflow.log_param(\"batch_size\", CONFIG['batch_size'])\n",
    "    mlflow.log_param(\"learning_rate\", CONFIG['learning_rate'])\n",
    "    mlflow.log_param(\"weight_decay\", CONFIG['weight_decay'])\n",
    "    mlflow.log_param(\"max_epochs\", CONFIG['max_epochs'])\n",
    "    mlflow.log_param(\"pretrained\", CONFIG['pretrained'])\n",
    "    mlflow.log_param(\"mixed_precision\", CONFIG['mixed_precision'])\n",
    "    mlflow.log_param(\"test_on_subset\", CONFIG['test_on_subset'])\n",
    "    if CONFIG['test_on_subset']:\n",
    "        mlflow.log_param(\"subset_size\", CONFIG['subset_size'])\n",
    "    mlflow.log_param(\"image_size\", CONFIG['image_size'])\n",
    "    mlflow.log_param(\"num_classes\", CONFIG['num_classes'])\n",
    "    mlflow.set_tag(\"phase\", \"Phase 1 - Baseline Test\")\n",
    "    mlflow.set_tag(\"status\", \"training\")\n",
    "\n",
    "print(f\"\\nüìä Training Configuration:\")\n",
    "print(f\"   - Model: {CONFIG['model_name']}\")\n",
    "print(f\"   - Max Epochs: {CONFIG['max_epochs']}\")\n",
    "print(f\"   - Early Stopping Patience: {CONFIG['early_stopping_patience']}\")\n",
    "print(f\"   - Device: {device}\")\n",
    "print(f\"\\nüöÄ Starting training...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    for epoch in range(CONFIG['max_epochs']):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Epoch {epoch+1}/{CONFIG['max_epochs']}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, scaler, epoch\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, _, _ = validate(\n",
    "            model, val_loader, criterion, device, desc=\"Val\"\n",
    "        )\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Log to MLflow\n",
    "        if MLFLOW_AVAILABLE:\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "            mlflow.log_metric(\"train_acc\", train_acc, step=epoch)\n",
    "            mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "            mlflow.log_metric(\"val_acc\", val_acc, step=epoch)\n",
    "            mlflow.log_metric(\"learning_rate\", optimizer.param_groups[0]['lr'], step=epoch)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"\\nüìä Epoch {epoch+1} Summary:\")\n",
    "        print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"   Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "        print(f\"   LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # Save best model\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'val_acc': val_acc,\n",
    "                'config': CONFIG\n",
    "            }, best_model_path)\n",
    "            \n",
    "            print(f\"   ‚úÖ New best model saved! (Val Loss: {val_loss:.4f})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"   ‚è≥ Patience: {patience_counter}/{CONFIG['early_stopping_patience']}\")\n",
    "            \n",
    "            if patience_counter >= CONFIG['early_stopping_patience']:\n",
    "                print(f\"\\n‚èπÔ∏è  Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è  Training interrupted by user\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERROR during training: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"TRAINING COMPLETED\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\n‚è±Ô∏è  Total Training Time: {training_time/60:.2f} minutes\")\n",
    "print(f\"‚úÖ Best model saved to: {best_model_path}\")\n",
    "print(f\"\\nüìä Best Validation Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "if MLFLOW_AVAILABLE:\n",
    "    mlflow.log_metric(\"training_time_minutes\", training_time/60)\n",
    "    mlflow.log_metric(\"best_val_loss\", best_val_loss)\n",
    "    mlflow.set_tag(\"status\", \"completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Plot Training History\n",
    "\n",
    "Visualize training and validation curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(epochs_range, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "axes[0].plot(epochs_range, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[0].set_ylabel('Loss', fontweight='bold')\n",
    "axes[0].set_title('Training and Validation Loss', fontweight='bold', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(epochs_range, history['train_acc'], 'b-', label='Train Acc', linewidth=2)\n",
    "axes[1].plot(epochs_range, history['val_acc'], 'r-', label='Val Acc', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[1].set_ylabel('Accuracy (%)', fontweight='bold')\n",
    "axes[1].set_title('Training and Validation Accuracy', fontweight='bold', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'resnet50_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Training history plot saved\")\n",
    "\n",
    "# Log to MLflow\n",
    "if MLFLOW_AVAILABLE:\n",
    "    mlflow.log_artifact(str(RESULTS_DIR / 'resnet50_training_history.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Evaluate on Test Set\n",
    "\n",
    "Load best model and evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"EVALUATING ON TEST SET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"\\n‚úÖ Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc, test_preds, test_labels = validate(\n",
    "    model, test_loader, criterion, device, desc=\"Test\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Test Set Results:\")\n",
    "print(f\"   - Test Loss: {test_loss:.4f}\")\n",
    "print(f\"   - Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nüìã Classification Report:\\n\")\n",
    "print(classification_report(\n",
    "    test_labels, \n",
    "    test_preds, \n",
    "    target_names=CONFIG['class_names'],\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "print(f\"\\nüìä Confusion Matrix:\\n\")\n",
    "print(cm)\n",
    "\n",
    "# Log to MLflow\n",
    "if MLFLOW_AVAILABLE:\n",
    "    mlflow.log_metric(\"test_loss\", test_loss)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_acc)\n",
    "    \n",
    "    # Calculate per-class metrics\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        test_labels, test_preds, average=None\n",
    "    )\n",
    "    \n",
    "    for i, class_name in enumerate(CONFIG['class_names']):\n",
    "        mlflow.log_metric(f\"test_precision_{class_name}\", precision[i])\n",
    "        mlflow.log_metric(f\"test_recall_{class_name}\", recall[i])\n",
    "        mlflow.log_metric(f\"test_f1_{class_name}\", f1[i])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Visualize Confusion Matrix\n",
    "\n",
    "Create publication-quality confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=CONFIG['class_names'],\n",
    "    yticklabels=CONFIG['class_names'],\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "plt.ylabel('True Label', fontweight='bold', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontweight='bold', fontsize=12)\n",
    "plt.title(f\"Confusion Matrix - {CONFIG['model_name']} (Test Set)\", fontweight='bold', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'resnet50_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Confusion matrix saved\")\n",
    "\n",
    "# Log to MLflow\n",
    "if MLFLOW_AVAILABLE:\n",
    "    mlflow.log_artifact(str(RESULTS_DIR / 'resnet50_confusion_matrix.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Summary Report\n",
    "\n",
    "Final summary of baseline test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BASELINE MODEL TEST - SUMMARY REPORT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n‚úÖ COMPLETED TASKS:\")\n",
    "print(\"   [‚úì] Created PyTorch Dataset and DataLoader\")\n",
    "print(\"   [‚úì] Loaded ResNet-50 baseline model\")\n",
    "print(\"   [‚úì] Trained on preprocessed CLAHE-enhanced images\")\n",
    "print(\"   [‚úì] Applied class weights for imbalance\")\n",
    "print(\"   [‚úì] Used mixed precision training (FP16)\")\n",
    "print(\"   [‚úì] Monitored GPU memory usage\")\n",
    "print(\"   [‚úì] Saved best model checkpoint\")\n",
    "print(\"   [‚úì] Logged results to MLflow\")\n",
    "\n",
    "print(\"\\nüìä FINAL RESULTS:\")\n",
    "print(f\"   - Model: {CONFIG['model_name']}\")\n",
    "print(f\"   - Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"   - Test Loss: {test_loss:.4f}\")\n",
    "print(f\"   - Training Time: {training_time/60:.2f} minutes\")\n",
    "print(f\"   - Best Val Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "if CONFIG['test_on_subset']:\n",
    "    print(f\"\\n‚ö†Ô∏è  SUBSET MODE:\")\n",
    "    print(f\"   - Trained on {len(train_dataset_use):,} images (subset)\")\n",
    "    print(f\"   - To train on FULL dataset: Set CONFIG['test_on_subset'] = False\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ FULL DATASET MODE:\")\n",
    "    print(f\"   - Trained on {len(train_dataset_use):,} images (full dataset)\")\n",
    "\n",
    "print(\"\\nüéØ PHASE 1 STATUS:\")\n",
    "if test_acc >= 70.0:\n",
    "    print(f\"   ‚úÖ SUCCESS: Achieved {test_acc:.2f}% accuracy (>70% target)\")\n",
    "    print(f\"   ‚úÖ Training pipeline verified and working!\")\n",
    "    print(f\"   ‚úÖ Ready to move to Phase 2 (Systematic Experimentation)\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  WARNING: Achieved {test_acc:.2f}% accuracy (<70% target)\")\n",
    "    print(f\"   üí° Suggestions:\")\n",
    "    print(f\"      - Check if using subset mode (set test_on_subset=False)\")\n",
    "    print(f\"      - Train for more epochs\")\n",
    "    print(f\"      - Verify data preprocessing\")\n",
    "\n",
    "print(\"\\nüìÅ OUTPUT FILES:\")\n",
    "print(f\"   - Best model: {best_model_path}\")\n",
    "print(f\"   - Training history: {RESULTS_DIR / 'resnet50_training_history.png'}\")\n",
    "print(f\"   - Confusion matrix: {RESULTS_DIR / 'resnet50_confusion_matrix.png'}\")\n",
    "\n",
    "if MLFLOW_AVAILABLE:\n",
    "    print(f\"\\nüìä MLFLOW:\")\n",
    "    print(f\"   - Experiment: crossvit-covid19-classification\")\n",
    "    print(f\"   - Run name: resnet50-baseline-seed-{CONFIG['seed']}\")\n",
    "    print(f\"   - View results: mlflow ui ‚Üí http://localhost:5000\")\n",
    "\n",
    "print(\"\\nüéØ NEXT STEPS:\")\n",
    "if test_acc >= 70.0:\n",
    "    print(\"   1. Optional: Create 05_augmentation_test.ipynb to test augmentation strategies\")\n",
    "    print(\"   2. Or skip to Phase 2: Start systematic experiments (notebooks 06-11)\")\n",
    "    print(\"   3. Train all 6 models with 5 seeds each (30 total runs)\")\n",
    "    print(\"   4. Use MLflow to track all experiments\")\n",
    "else:\n",
    "    print(\"   1. Re-run with CONFIG['test_on_subset'] = False (if using subset)\")\n",
    "    print(\"   2. Increase max_epochs to 50\")\n",
    "    print(\"   3. Debug any preprocessing issues\")\n",
    "    print(\"   4. Achieve >70% before moving to Phase 2\")\n",
    "\n",
    "print(\"\\n‚úÖ Baseline model test complete! Phase 1 finished.\")\n",
    "print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "# End MLflow run\n",
    "if MLFLOW_AVAILABLE:\n",
    "    mlflow.end_run()\n",
    "    print(\"‚úÖ MLflow run ended successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}